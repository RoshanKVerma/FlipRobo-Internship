{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05243e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to display all the header tags from wikipedia.org.\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen('https://en.wikipedia.org/wiki/Main_Page')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "titles = bs.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "print('List all the header tags :', *titles, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5223fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) \n",
    "#  and make data frame.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Downloading imdb top 250 movie's data\n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "movies = soup.select('td.titleColumn')\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value')\n",
    "        for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a empty list for storing\n",
    "# movie information\n",
    "list = []\n",
    "\n",
    "# Iterating over movies to extract\n",
    "# each movie's details\n",
    "for index in range(0,100):\n",
    "    \n",
    "    # Separating movie into: 'place',\n",
    "    # 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"place\": place,\n",
    "            \"movie_title\": movie_title,\n",
    "            \"rating\": ratings[index],\n",
    "            \"year\": year,\n",
    "            \"star_cast\": crew[index],\n",
    "            }\n",
    "    list.append(data)\n",
    "\n",
    "# printing movie details with its rating.\n",
    "\n",
    "\n",
    "##.......##\n",
    "df = pd.DataFrame(list)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc80d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of\n",
    "#    release) and make data frame.\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Downloading imdb top 250 movie's data\n",
    "url = 'https://www.imdb.com/india/top-rated-indian-movies'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "movies = soup.select('td.titleColumn')\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value')\n",
    "        for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a empty list for storing\n",
    "# movie information\n",
    "list = []\n",
    "\n",
    "# Iterating over movies to extract\n",
    "# each movie's details\n",
    "for index in range(0,100):\n",
    "    \n",
    "    # Separating movie into: 'place',\n",
    "    # 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"place\": place,\n",
    "            \"movie_title\": movie_title,\n",
    "            \"rating\": ratings[index],\n",
    "            \"year\": year,\n",
    "            \"star_cast\": crew[index],\n",
    "            }\n",
    "    list.append(data)\n",
    "\n",
    "# printing movie details with its rating.\n",
    "\n",
    "\n",
    "##.......##\n",
    "df = pd.DataFrame(list)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b2f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write s python program to display list of respected former presidents of India(i.e. Name , Term of office)\n",
    "#  from https://presidentofindia.nic.in/former-presidents.htm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url=\"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "test=[]\n",
    "\n",
    "President_Name=[]\n",
    "Name=soup.find_all('h3')\n",
    "for i in Name:\n",
    "    President_Name.append(i.text)\n",
    "    \n",
    "    \n",
    "Terms=[]    \n",
    "Term_of_Year=soup.find_all(attrs={'class':'presidentListing'})\n",
    "for i in Term_of_Year:\n",
    "    Terms.append(i.text.split(':')[1])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "Data={'Presidents Name':President_Name,'Term of Office':Terms}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "Test=[]\n",
    "Country=[]\n",
    "Rank=[]\n",
    "Matches=[]\n",
    "Points=[]\n",
    "Rating=[]\n",
    "\n",
    "\n",
    "TeamRank=soup.find('td',class_='rankings-block__banner--pos')\n",
    "Rank.append(TeamRank.text)\n",
    "\n",
    "TotalMatches=soup.find('td',class_='rankings-block__banner--matches')\n",
    "Matches.append(TotalMatches.text)\n",
    "\n",
    "TotalPoints=soup.find('td',class_='rankings-block__banner--points')\n",
    "Points.append(TotalPoints.text)\n",
    "\n",
    "TeamRatings=soup.find('td',class_='rankings-block__banner--rating u-text-right')\n",
    "Rating.append(TeamRatings.text)\n",
    "\n",
    "\n",
    "TeamRank=soup.findAll('td',class_='table-body__cell table-body__cell--position u-text-right')\n",
    "for i in TeamRank:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "TeamName=soup.find_all('span',class_='u-hide-phablet')\n",
    "for i in TeamName:\n",
    "    Country.append(i.text)\n",
    "    \n",
    "TotalMatches=soup.findAll('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "for i in TotalMatches:\n",
    "        Test.append(i.text)\n",
    "        \n",
    "Matches.extend(Test[0:-1:2])\n",
    "Points.extend(Test[1::2])\n",
    "\n",
    "\n",
    "TeamRatings=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    \n",
    "for i in TeamRatings:\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "Data={\"Rank\":Rank,\"Country Name\":Country,\"Matches Played\":Matches,\"Total Points\":Points,\"Country Rating\":Rating}\n",
    "\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8c3ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "TestRank=[]\n",
    "TestName=[]\n",
    "TestCountry=[]\n",
    "TestRating=[]\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Country=[]\n",
    "Rating=[]\n",
    "\n",
    "BatRank=soup.find('span',class_='rankings-block__pos-number')\n",
    "TestRank.append(BatRank.text.split()[0])\n",
    "\n",
    "BatName=soup.find('div',class_='rankings-block__banner--name-large')\n",
    "TestName.append(BatName.text)\n",
    "\n",
    "BatCountry=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "TestCountry.append(BatCountry.text.split()[0])\n",
    "\n",
    "BatRating=soup.find('div',class_='rankings-block__banner--rating')\n",
    "TestRating.append(BatRating.text)\n",
    "\n",
    "BatRank=soup.findAll('span',class_='rankings-table__pos-number')\n",
    "for i in BatRank:\n",
    "    TestRank.append(i.text.split()[0])\n",
    "    Rank=TestRank[0:10]\n",
    "\n",
    "BatName=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for i in BatName:\n",
    "    TestName.append(i.text.split())\n",
    "    Name=TestName[0:10]\n",
    "    \n",
    "BatCountry=soup.find_all('span',class_='table-body__logo-text')\n",
    "for i in BatCountry:\n",
    "    TestCountry.append(i.text.split()[0])\n",
    "    Country=TestCountry[0:10]\n",
    "    \n",
    "    \n",
    "BatRating=soup.find_all('td',class_='table-body__cell rating')\n",
    "for i in BatRating:\n",
    "    TestRating.append(i.text)\n",
    "    Rating=TestRating[0:10]\n",
    "    \n",
    "    \n",
    "Data={\"Rank\":Rank,\"Player Name\":Name,\"Country Name\":Country,\"Player Ratings\":Rating}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ffaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "TestRank=[]\n",
    "TestName=[]\n",
    "TestCountry=[]\n",
    "TestRating=[]\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Country=[]\n",
    "Rating=[]\n",
    "\n",
    "\n",
    "\n",
    "BatRank=soup.find('span',class_='rankings-block__pos-number')\n",
    "TestRank.append(BatRank.text.split()[0])\n",
    "\n",
    "BatName=soup.find('div',class_='rankings-block__banner--name-large')\n",
    "TestName.append(BatName.text)\n",
    "\n",
    "BatCountry=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "TestCountry.append(BatCountry.text.split()[0])\n",
    "\n",
    "BatRating=soup.find('div',class_='rankings-block__banner--rating')\n",
    "TestRating.append(BatRating.text)\n",
    "\n",
    "BatRank=soup.findAll('span',class_='rankings-table__pos-number')\n",
    "for i in BatRank:\n",
    "    TestRank.append(i.text.split()[0])\n",
    "    Rank=TestRank[0:10]\n",
    "\n",
    "BatName=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for i in BatName:\n",
    "    TestName.append(i.text.split())\n",
    "    Name=TestName[0:10]\n",
    "    \n",
    "BatCountry=soup.find_all('span',class_='table-body__logo-text')\n",
    "for i in BatCountry:\n",
    "    TestCountry.append(i.text.split()[0])\n",
    "    Country=TestCountry[0:10]\n",
    "    \n",
    "    \n",
    "BatRating=soup.find_all('td',class_='table-body__cell rating')\n",
    "for i in BatRating:\n",
    "    TestRating.append(i.text)\n",
    "    Rating=TestRating[0:10]\n",
    "    \n",
    "    \n",
    "Data={\"Rank\":Rank,\"Player Name\":Name,\"Country Name\":Country,\"Player Ratings\":Rating}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "Test=[]\n",
    "Country=[]\n",
    "Rank=[]\n",
    "Matches=[]\n",
    "Points=[]\n",
    "Rating=[]\n",
    "\n",
    "\n",
    "TeamRank=soup.find('td',class_='rankings-block__banner--pos')\n",
    "Rank.append(TeamRank.text)\n",
    "\n",
    "TotalMatches=soup.find('td',class_='rankings-block__banner--matches')\n",
    "Matches.append(TotalMatches.text)\n",
    "\n",
    "TotalPoints=soup.find('td',class_='rankings-block__banner--points')\n",
    "Points.append(TotalPoints.text)\n",
    "\n",
    "TeamRatings=soup.find('td',class_='rankings-block__banner--rating u-text-right')\n",
    "Rating.append(TeamRatings.text)\n",
    "\n",
    "\n",
    "TeamRank=soup.findAll('td',class_='table-body__cell table-body__cell--position u-text-right')\n",
    "for i in TeamRank:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "TeamName=soup.find_all('span',class_='u-hide-phablet')\n",
    "for i in TeamName:\n",
    "    Country.append(i.text)\n",
    "    \n",
    "TotalMatches=soup.findAll('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "for i in TotalMatches:\n",
    "        Test.append(i.text)\n",
    "        \n",
    "Matches.extend(Test[0:-1:2])\n",
    "Points.extend(Test[1::2])\n",
    "\n",
    "\n",
    "TeamRatings=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    \n",
    "for i in TeamRatings:\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "Data={\"Rank\":Rank,\"Country Name\":Country,\"Matches Played\":Matches,\"Total Points\":Points,\"Country Rating\":Rating}\n",
    "\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "TestRank=[]\n",
    "TestName=[]\n",
    "TestCountry=[]\n",
    "TestRating=[]\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Country=[]\n",
    "Rating=[]\n",
    "\n",
    "BatRank=soup.find('span',class_='rankings-block__pos-number')\n",
    "TestRank.append(BatRank.text.split()[0])\n",
    "\n",
    "BatName=soup.find('div',class_='rankings-block__banner--name-large')\n",
    "TestName.append(BatName.text)\n",
    "\n",
    "BatCountry=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "TestCountry.append(BatCountry.text.split()[0])\n",
    "\n",
    "BatRating=soup.find('div',class_='rankings-block__banner--rating')\n",
    "TestRating.append(BatRating.text)\n",
    "\n",
    "BatRank=soup.findAll('span',class_='rankings-table__pos-number')\n",
    "for i in BatRank:\n",
    "    TestRank.append(i.text.split()[0])\n",
    "    Rank=TestRank[0:10]\n",
    "\n",
    "BatName=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for i in BatName:\n",
    "    TestName.append(i.text.split())\n",
    "    Name=TestName[0:10]\n",
    "    \n",
    "BatCountry=soup.find_all('span',class_='table-body__logo-text')\n",
    "for i in BatCountry:\n",
    "    TestCountry.append(i.text.split()[0])\n",
    "    Country=TestCountry[0:10]\n",
    "    \n",
    "    \n",
    "BatRating=soup.find_all('td',class_='table-body__cell rating')\n",
    "for i in BatRating:\n",
    "    TestRating.append(i.text)\n",
    "    Rating=TestRating[0:10]\n",
    "    \n",
    "    \n",
    "Data={\"Rank\":Rank,\"Player Name\":Name,\"Country Name\":Country,\"Player Ratings\":Rating}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b947ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "TestRank=[]\n",
    "TestName=[]\n",
    "TestCountry=[]\n",
    "TestRating=[]\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Country=[]\n",
    "Rating=[]\n",
    "\n",
    "BatRank=soup.find('span',class_='rankings-block__pos-number')\n",
    "TestRank.append(BatRank.text.split()[0])\n",
    "\n",
    "BatName=soup.find('div',class_='rankings-block__banner--name-large')\n",
    "TestName.append(BatName.text)\n",
    "\n",
    "BatCountry=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "TestCountry.append(BatCountry.text.split()[0])\n",
    "\n",
    "BatRating=soup.find('div',class_='rankings-block__banner--rating')\n",
    "TestRating.append(BatRating.text)\n",
    "\n",
    "BatRank=soup.findAll('span',class_='rankings-table__pos-number')\n",
    "for i in BatRank:\n",
    "    TestRank.append(i.text.split()[0])\n",
    "    Rank=TestRank[0:10]\n",
    "\n",
    "BatName=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for i in BatName:\n",
    "    TestName.append(i.text.split())\n",
    "    Name=TestName[0:10]\n",
    "    \n",
    "BatCountry=soup.find_all('span',class_='table-body__logo-text')\n",
    "for i in BatCountry:\n",
    "    TestCountry.append(i.text.split()[0])\n",
    "    Country=TestCountry[0:10]\n",
    "    \n",
    "    \n",
    "BatRating=soup.find_all('td',class_='table-body__cell rating')\n",
    "for i in BatRating:\n",
    "    TestRating.append(i.text)\n",
    "    Rating=TestRating[0:10]\n",
    "    \n",
    "    \n",
    "Data={\"Rank\":Rank,\"Player Name\":Name,\"Country Name\":Country,\"Player Ratings\":Rating}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "# i) Headline\n",
    "# ii) Time\n",
    "# iii) News Link\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "HeadLine=[]\n",
    "Time=[]\n",
    "Link=[]\n",
    "\n",
    "\n",
    "for i in soup.find_all('a',class_='LatestNews-headline'):\n",
    "    HeadLine.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('time',class_='LatestNews-timestamp'):\n",
    "    Time.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('a',class_='LatestNews-headline'):\n",
    "    Link.append(i.get('href'))\n",
    "\n",
    "    \n",
    "Data={'News Headlines':HeadLine,'Time of News':Time,'Link for News':Link}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e40ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "# https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "# Scrape below mentioned details :\n",
    "# i) Paper Title\n",
    "# ii) Authors\n",
    "# iii) Published Date\n",
    "# iv) Paper URL\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "Test=[]\n",
    "Title=[]\n",
    "Writers=[]\n",
    "Date=[]\n",
    "Links=[]\n",
    "\n",
    "Test=soup.find_all('h2',class_='sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR')\n",
    "for i in Test:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "Test=soup.find_all('span',class_='sc-1w3fpd7-0 pgLAT')\n",
    "for i in Test:\n",
    "    Writers.append(i.text)\n",
    "    \n",
    "Test=soup.find_all('span',class_='sc-1thf9ly-2 bKddwo')\n",
    "for i in Test:\n",
    "    Date.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('a',class_='sc-5smygv-0 nrDZj'):\n",
    "    Links.append(i.get('href'))\n",
    "\n",
    "\n",
    "\n",
    "Data={'Paper Title':Title,'Authors':Writers,'Published Date':Date,'Paper URL':Links}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape mentioned details from dineout.co.in :\n",
    "# i) Restaurant name\n",
    "# ii) Cuisine\n",
    "# iii) Location\n",
    "# iv) Ratings\n",
    "# v) Image URL\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "Test=[]\n",
    "Resturants=[]\n",
    "Cuisine=[]\n",
    "Location=[]\n",
    "Stars=[]\n",
    "Image=[]\n",
    "\n",
    "Test=soup.find_all('a',class_='restnt-name ellipsis')\n",
    "for i in Test:\n",
    "    Resturants.append(i.text)\n",
    "\n",
    "    \n",
    "Test=soup.find_all('div',class_='restnt-loc ellipsis')\n",
    "for i in Test:\n",
    "    Location.append(i.text)\n",
    "    \n",
    "Test=soup.find_all('span',class_='double-line-ellipsis')\n",
    "for i in Test:\n",
    "    Cuisine.append(i.text.split()[6::])\n",
    "    \n",
    "    \n",
    "Test=soup.find_all('div',class_='restnt-rating rating-4')\n",
    "for i in Test:\n",
    "    Stars.append(i.text)\n",
    "\n",
    "for img in soup.find_all('img',class_='no-img'):\n",
    "    Image.append(img.get('data-src'))\n",
    "\n",
    "    \n",
    "Data={'Resturants Name':Resturants,'Cuisine':Cuisine,'Location':Location,'Rating':Stars,'Image URL':Image}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851595f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape the details of top publications from Google Scholar from\n",
    "#   https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "# i) Rank\n",
    "# ii) Publication\n",
    "# iii) h5-index\n",
    "# iv) h5-median\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://scholar.google.com/citations?view_op=top_venues&hl=en'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "Test=[]\n",
    "Rank=[]\n",
    "Titles=[]\n",
    "Avg=[]\n",
    "Median=[]\n",
    "\n",
    "Test=soup.find_all('td',class_='gsc_mvt_p')\n",
    "for i in Test:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "    \n",
    "\n",
    "Test=soup.find_all('td',class_='gsc_mvt_t')\n",
    "for i in Test:\n",
    "    Titles.append(i.text)\n",
    "\n",
    "    \n",
    "Test=soup.find_all('a',class_='gs_ibl gsc_mp_anchor')\n",
    "for i in Test:\n",
    "    Avg.append(i.text)\n",
    "    \n",
    "\n",
    "Test=soup.find_all('span',class_='gs_ibl gsc_mp_anchor')\n",
    "for i in Test:\n",
    "    Median.append(i.text)\n",
    "\n",
    "\n",
    "    \n",
    "Data={'Rank':Rank,'Publication':Titles,'h5-Index':Avg,'h5-Median':Median}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada43d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
