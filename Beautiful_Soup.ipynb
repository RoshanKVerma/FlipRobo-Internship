{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce1198a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\roshanv\\anaconda3\\lib\\site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\roshanv\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=7097f083ee0b71d196b58ab88dc02310e3d61a702a11eeb8a9dd0f96daa6bcd5\n",
      "  Stored in directory: c:\\users\\roshanv\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191251ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\roshanv\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\roshanv\\anaconda3\\lib\\site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\roshanv\\anaconda3\\lib\\site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\roshanv\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\roshanv\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05243e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all the header tags :\n",
      "\n",
      "<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\" style=\"display: none\">Main Page</h1>\n",
      "\n",
      "<h1><span class=\"mw-headline\" id=\"Welcome_to_Wikipedia\">Welcome to <a href=\"/wiki/Wikipedia\" title=\"Wikipedia\">Wikipedia</a></span></h1>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "\n",
      "<h2>Navigation menu</h2>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span class=\"vector-menu-heading-label\">Personal tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span class=\"vector-menu-heading-label\">Namespaces</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span class=\"vector-menu-heading-label\">Views</span>\n",
      "</h3>\n",
      "\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span class=\"vector-menu-heading-label\">Navigation</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span class=\"vector-menu-heading-label\">Contribute</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span class=\"vector-menu-heading-label\">Tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span class=\"vector-menu-heading-label\">Print/export</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span class=\"vector-menu-heading-label\">In other projects</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span class=\"vector-menu-heading-label\">Languages</span>\n",
      "</h3>\n"
     ]
    }
   ],
   "source": [
    "#Write a python program to display all the header tags from wikipedia.org.\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen('https://en.wikipedia.org/wiki/Main_Page')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "titles = bs.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "print('List all the header tags :', *titles, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5223fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   place                        movie_title             rating  year  \\\n",
      "0      1           The Shawshank Redemption  9.234512632940211  1994   \n",
      "1      2                      The Godfather  9.156487240335014  1972   \n",
      "2      3                    The Dark Knight   8.98680645530797  2008   \n",
      "3      4              The Godfather Part II  8.984648293572267  1974   \n",
      "4      5                       12 Angry Men  8.948897669577086  1957   \n",
      "..   ...                                ...                ...   ...   \n",
      "95    96                             Jagten  8.255584701495112  2012   \n",
      "96    97  M - Eine Stadt sucht einen Mörder  8.254676472789424  1931   \n",
      "97    98                 North by Northwest  8.252984757557929  1959   \n",
      "98    99                            Vertigo  8.247314672279423  1958   \n",
      "99    10                       Idi i smotri  8.246642763834718  1985   \n",
      "\n",
      "                                            star_cast  \n",
      "0   Frank Darabont (dir.), Tim Robbins, Morgan Fre...  \n",
      "1   Francis Ford Coppola (dir.), Marlon Brando, Al...  \n",
      "2   Christopher Nolan (dir.), Christian Bale, Heat...  \n",
      "3   Francis Ford Coppola (dir.), Al Pacino, Robert...  \n",
      "4       Sidney Lumet (dir.), Henry Fonda, Lee J. Cobb  \n",
      "..                                                ...  \n",
      "95  Thomas Vinterberg (dir.), Mads Mikkelsen, Thom...  \n",
      "96      Fritz Lang (dir.), Peter Lorre, Ellen Widmann  \n",
      "97  Alfred Hitchcock (dir.), Cary Grant, Eva Marie...  \n",
      "98  Alfred Hitchcock (dir.), James Stewart, Kim Novak  \n",
      "99  Elem Klimov (dir.), Aleksey Kravchenko, Olga M...  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) \n",
    "#  and make data frame.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Downloading imdb top 250 movie's data\n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "movies = soup.select('td.titleColumn')\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value')\n",
    "        for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a empty list for storing\n",
    "# movie information\n",
    "list = []\n",
    "\n",
    "# Iterating over movies to extract\n",
    "# each movie's details\n",
    "for index in range(0,100):\n",
    "    \n",
    "    # Separating movie into: 'place',\n",
    "    # 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"place\": place,\n",
    "            \"movie_title\": movie_title,\n",
    "            \"rating\": ratings[index],\n",
    "            \"year\": year,\n",
    "            \"star_cast\": crew[index],\n",
    "            }\n",
    "    list.append(data)\n",
    "\n",
    "# printing movie details with its rating.\n",
    "\n",
    "\n",
    "##.......##\n",
    "df = pd.DataFrame(list)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc80d3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   place                  movie_title             rating  year  \\\n",
      "0      1   Rocketry: The Nambi Effect  8.485786320096842  2022   \n",
      "1      2                   Anbe Sivam  8.397879377265177  2003   \n",
      "2      3                      Golmaal  8.390262034166765  1979   \n",
      "3      4                     Jai Bhim   8.38517772962922  2021   \n",
      "4      5                      Nayakan   8.38452905658654  1987   \n",
      "..   ...                          ...                ...   ...   \n",
      "95    96              Rang De Basanti  8.014191708951078  2006   \n",
      "96    97                       Baasha   8.01231058896825  1995   \n",
      "97    98  Baahubali 2: The Conclusion   8.00783939363439  2017   \n",
      "98    99                       Masaan  8.007161087076355  2015   \n",
      "99    10                      Kahaani  8.005711424866748  2012   \n",
      "\n",
      "                                            star_cast  \n",
      "0                   Madhavan (dir.), Madhavan, Simran  \n",
      "1            Sundar C. (dir.), Kamal Haasan, Madhavan  \n",
      "2   Hrishikesh Mukherjee (dir.), Amol Palekar, Bin...  \n",
      "3         T.J. Gnanavel (dir.), Suriya, Lijo Mol Jose  \n",
      "4   Mani Ratnam (dir.), Kamal Haasan, Saranya Ponv...  \n",
      "..                                                ...  \n",
      "95  Rakeysh Omprakash Mehra (dir.), Aamir Khan, So...  \n",
      "96          Suresh Krishna (dir.), Rajinikanth, Nagma  \n",
      "97     S.S. Rajamouli (dir.), Prabhas, Rana Daggubati  \n",
      "98  Neeraj Ghaywan (dir.), Richa Chadha, Sanjay Mi...  \n",
      "99  Sujoy Ghosh (dir.), Vidya Balan, Parambrata Ch...  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of\n",
    "#    release) and make data frame.\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Downloading imdb top 250 movie's data\n",
    "url = 'https://www.imdb.com/india/top-rated-indian-movies'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "movies = soup.select('td.titleColumn')\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value')\n",
    "        for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a empty list for storing\n",
    "# movie information\n",
    "list = []\n",
    "\n",
    "# Iterating over movies to extract\n",
    "# each movie's details\n",
    "for index in range(0,100):\n",
    "    \n",
    "    # Separating movie into: 'place',\n",
    "    # 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"place\": place,\n",
    "            \"movie_title\": movie_title,\n",
    "            \"rating\": ratings[index],\n",
    "            \"year\": year,\n",
    "            \"star_cast\": crew[index],\n",
    "            }\n",
    "    list.append(data)\n",
    "\n",
    "# printing movie details with its rating.\n",
    "\n",
    "\n",
    "##.......##\n",
    "df = pd.DataFrame(list)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "ff5b2f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Presidents Name</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022 \\nhttps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017 \\nhttp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012 \\nhttp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007 \\nhttp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Presidents Name  \\\n",
       "0           Shri Ram Nath Kovind (birth - 1945)   \n",
       "1             Shri Pranab Mukherjee (1935-2020)   \n",
       "2   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "3            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "4            Shri K. R. Narayanan (1920 - 2005)   \n",
       "5           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "6               Shri R Venkataraman (1910-2009)   \n",
       "7                  Giani Zail Singh (1916-1994)   \n",
       "8         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "9          Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "10     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "11                 Dr. Zakir Husain (1897-1969)   \n",
       "12     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "13             Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                       Term of Office  \n",
       "0              25 July, 2017 to 25 July, 2022 \\nhttps  \n",
       "1               25 July, 2012 to 25 July, 2017 \\nhttp  \n",
       "2               25 July, 2007 to 25 July, 2012 \\nhttp  \n",
       "3               25 July, 2002 to 25 July, 2007 \\nhttp  \n",
       "4                   25 July, 1997 to 25 July, 2002 \\n  \n",
       "5                   25 July, 1992 to 25 July, 1997 \\n  \n",
       "6                   25 July, 1987 to 25 July, 1992 \\n  \n",
       "7                   25 July, 1982 to 25 July, 1987 \\n  \n",
       "8                   25 July, 1977 to 25 July, 1982 \\n  \n",
       "9              24 August, 1974 to 11 February, 1977\\n  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                      13 May, 1967 to 3 May, 1969\\n  \n",
       "12                     13 May, 1962 to 13 May, 1967\\n  \n",
       "13                 26 January, 1950 to 13 May, 1962\\n  "
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write s python program to display list of respected former presidents of India(i.e. Name , Term of office)\n",
    "#  from https://presidentofindia.nic.in/former-presidents.htm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url=\"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "test=[]\n",
    "\n",
    "President_Name=[]\n",
    "Name=soup.find_all('h3')\n",
    "for i in Name:\n",
    "    President_Name.append(i.text)\n",
    "    \n",
    "    \n",
    "Terms=[]    \n",
    "Term_of_Year=soup.find_all(attrs={'class':'presidentListing'})\n",
    "for i in Term_of_Year:\n",
    "    Terms.append(i.text.split(':')[1])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "Data={'Presidents Name':President_Name,'Term of Office':Terms}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e5c7c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "Test=[]\n",
    "Country=[]\n",
    "Rank=[]\n",
    "Matches=[]\n",
    "Points=[]\n",
    "Rating=[]\n",
    "\n",
    "\n",
    "TeamRank=soup.find('td',class_='rankings-block__banner--pos')\n",
    "Rank.append(TeamRank.text)\n",
    "\n",
    "TotalMatches=soup.find('td',class_='rankings-block__banner--matches')\n",
    "Matches.append(TotalMatches.text)\n",
    "\n",
    "TotalPoints=soup.find('td',class_='rankings-block__banner--points')\n",
    "Points.append(TotalPoints.text)\n",
    "\n",
    "TeamRatings=soup.find('td',class_='rankings-block__banner--rating u-text-right')\n",
    "Rating.append(TeamRatings.text)\n",
    "\n",
    "\n",
    "TeamRank=soup.findAll('td',class_='table-body__cell table-body__cell--position u-text-right')\n",
    "for i in TeamRank:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "TeamName=soup.find_all('span',class_='u-hide-phablet')\n",
    "for i in TeamName:\n",
    "    Country.append(i.text)\n",
    "    \n",
    "TotalMatches=soup.findAll('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "for i in TotalMatches:\n",
    "        Test.append(i.text)\n",
    "        \n",
    "Matches.extend(Test[0:-1:2])\n",
    "Points.extend(Test[1::2])\n",
    "\n",
    "\n",
    "TeamRatings=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    \n",
    "for i in TeamRatings:\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "Data={\"Rank\":Rank,\"Country Name\":Country,\"Matches Played\":Matches,\"Total Points\":Points,\"Country Rating\":Rating}\n",
    "\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "d8f8c3ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Player Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Imam-ul-Haq]</td>\n",
       "      <td>PAK</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[Rassie, van, der, Dussen]</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[Quinton, de, Kock]</td>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Virat, Kohli]</td>\n",
       "      <td>IND</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[Rohit, Sharma]</td>\n",
       "      <td>IND</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[Ross, Taylor]</td>\n",
       "      <td>NZ</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[David, Warner]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[Jonny, Bairstow]</td>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[Aaron, Finch]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                 Player Name Country Name Player Ratings\n",
       "0    1                  Babar Azam          PAK            892\n",
       "1    2               [Imam-ul-Haq]          PAK            815\n",
       "2    3  [Rassie, van, der, Dussen]           SA            789\n",
       "3    4         [Quinton, de, Kock]           SA            784\n",
       "4    5              [Virat, Kohli]          IND            767\n",
       "5    6             [Rohit, Sharma]          IND            763\n",
       "6    7              [Ross, Taylor]           NZ            744\n",
       "7    8             [David, Warner]          AUS            737\n",
       "8    9           [Jonny, Bairstow]          ENG            732\n",
       "9   10              [Aaron, Finch]          AUS            715"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "TestRank=[]\n",
    "TestName=[]\n",
    "TestCountry=[]\n",
    "TestRating=[]\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Country=[]\n",
    "Rating=[]\n",
    "\n",
    "BatRank=soup.find('span',class_='rankings-block__pos-number')\n",
    "TestRank.append(BatRank.text.split()[0])\n",
    "\n",
    "BatName=soup.find('div',class_='rankings-block__banner--name-large')\n",
    "TestName.append(BatName.text)\n",
    "\n",
    "BatCountry=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "TestCountry.append(BatCountry.text.split()[0])\n",
    "\n",
    "BatRating=soup.find('div',class_='rankings-block__banner--rating')\n",
    "TestRating.append(BatRating.text)\n",
    "\n",
    "BatRank=soup.findAll('span',class_='rankings-table__pos-number')\n",
    "for i in BatRank:\n",
    "    TestRank.append(i.text.split()[0])\n",
    "    Rank=TestRank[0:10]\n",
    "\n",
    "BatName=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for i in BatName:\n",
    "    TestName.append(i.text.split())\n",
    "    Name=TestName[0:10]\n",
    "    \n",
    "BatCountry=soup.find_all('span',class_='table-body__logo-text')\n",
    "for i in BatCountry:\n",
    "    TestCountry.append(i.text.split()[0])\n",
    "    Country=TestCountry[0:10]\n",
    "    \n",
    "    \n",
    "BatRating=soup.find_all('td',class_='table-body__cell rating')\n",
    "for i in BatRating:\n",
    "    TestRating.append(i.text)\n",
    "    Rating=TestRating[0:10]\n",
    "    \n",
    "    \n",
    "Data={\"Rank\":Rank,\"Player Name\":Name,\"Country Name\":Country,\"Player Ratings\":Rating}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "445ffaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Player Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Jasprit, Bumrah]</td>\n",
       "      <td>IND</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[Shaheen, Afridi]</td>\n",
       "      <td>PAK</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[Josh, Hazlewood]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Mujeeb, Ur, Rahman]</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[Mehedi, Hasan]</td>\n",
       "      <td>BAN</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[Matt, Henry]</td>\n",
       "      <td>NZ</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[Mohammad, Nabi]</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[Rashid, Khan]</td>\n",
       "      <td>AFG</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[Chris, Woakes]</td>\n",
       "      <td>ENG</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank           Player Name Country Name Player Ratings\n",
       "0    1           Trent Boult           NZ            697\n",
       "1    2     [Jasprit, Bumrah]          IND            682\n",
       "2    3     [Shaheen, Afridi]          PAK            681\n",
       "3    4     [Josh, Hazlewood]          AUS            679\n",
       "4    5  [Mujeeb, Ur, Rahman]          AFG            676\n",
       "5    6       [Mehedi, Hasan]          BAN            672\n",
       "6    7         [Matt, Henry]           NZ            663\n",
       "7    8      [Mohammad, Nabi]          AFG            657\n",
       "8    9        [Rashid, Khan]          AFG            651\n",
       "9   10       [Chris, Woakes]          ENG            640"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "TestRank=[]\n",
    "TestName=[]\n",
    "TestCountry=[]\n",
    "TestRating=[]\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Country=[]\n",
    "Rating=[]\n",
    "\n",
    "\n",
    "\n",
    "BatRank=soup.find('span',class_='rankings-block__pos-number')\n",
    "TestRank.append(BatRank.text.split()[0])\n",
    "\n",
    "BatName=soup.find('div',class_='rankings-block__banner--name-large')\n",
    "TestName.append(BatName.text)\n",
    "\n",
    "BatCountry=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "TestCountry.append(BatCountry.text.split()[0])\n",
    "\n",
    "BatRating=soup.find('div',class_='rankings-block__banner--rating')\n",
    "TestRating.append(BatRating.text)\n",
    "\n",
    "BatRank=soup.findAll('span',class_='rankings-table__pos-number')\n",
    "for i in BatRank:\n",
    "    TestRank.append(i.text.split()[0])\n",
    "    Rank=TestRank[0:10]\n",
    "\n",
    "BatName=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for i in BatName:\n",
    "    TestName.append(i.text.split())\n",
    "    Name=TestName[0:10]\n",
    "    \n",
    "BatCountry=soup.find_all('span',class_='table-body__logo-text')\n",
    "for i in BatCountry:\n",
    "    TestCountry.append(i.text.split()[0])\n",
    "    Country=TestCountry[0:10]\n",
    "    \n",
    "    \n",
    "BatRating=soup.find_all('td',class_='table-body__cell rating')\n",
    "for i in BatRating:\n",
    "    TestRating.append(i.text)\n",
    "    Rating=TestRating[0:10]\n",
    "    \n",
    "    \n",
    "Data={\"Rank\":Rank,\"Player Name\":Name,\"Country Name\":Country,\"Player Ratings\":Rating}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "04da18b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Matches Played</th>\n",
       "      <th>Total Points</th>\n",
       "      <th>Country Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>4,837</td>\n",
       "      <td>\\n                            167\\n           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>England</td>\n",
       "      <td>33</td>\n",
       "      <td>4,046</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India</td>\n",
       "      <td>32</td>\n",
       "      <td>3,219</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>31</td>\n",
       "      <td>3,019</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>30</td>\n",
       "      <td>2,768</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>930</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>30</td>\n",
       "      <td>1,962</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>495</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>8</td>\n",
       "      <td>351</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank  Country Name Matches Played Total Points  \\\n",
       "0     1     Australia             29        4,837   \n",
       "1     2       England             33        4,046   \n",
       "2     3  South Africa             35        4,157   \n",
       "3     4         India             32        3,219   \n",
       "4     5   New Zealand             31        3,019   \n",
       "5     6   West Indies             30        2,768   \n",
       "6     7    Bangladesh             12          930   \n",
       "7     8      Pakistan             30        1,962   \n",
       "8     9     Sri Lanka             11          495   \n",
       "9    10       Ireland              8          351   \n",
       "10   11      Zimbabwe              8            0   \n",
       "\n",
       "                                       Country Rating  \n",
       "0   \\n                            167\\n           ...  \n",
       "1                                                 123  \n",
       "2                                                 119  \n",
       "3                                                 101  \n",
       "4                                                  97  \n",
       "5                                                  92  \n",
       "6                                                  78  \n",
       "7                                                  65  \n",
       "8                                                  45  \n",
       "9                                                  44  \n",
       "10                                                  0  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "Test=[]\n",
    "Country=[]\n",
    "Rank=[]\n",
    "Matches=[]\n",
    "Points=[]\n",
    "Rating=[]\n",
    "\n",
    "\n",
    "TeamRank=soup.find('td',class_='rankings-block__banner--pos')\n",
    "Rank.append(TeamRank.text)\n",
    "\n",
    "TotalMatches=soup.find('td',class_='rankings-block__banner--matches')\n",
    "Matches.append(TotalMatches.text)\n",
    "\n",
    "TotalPoints=soup.find('td',class_='rankings-block__banner--points')\n",
    "Points.append(TotalPoints.text)\n",
    "\n",
    "TeamRatings=soup.find('td',class_='rankings-block__banner--rating u-text-right')\n",
    "Rating.append(TeamRatings.text)\n",
    "\n",
    "\n",
    "TeamRank=soup.findAll('td',class_='table-body__cell table-body__cell--position u-text-right')\n",
    "for i in TeamRank:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "TeamName=soup.find_all('span',class_='u-hide-phablet')\n",
    "for i in TeamName:\n",
    "    Country.append(i.text)\n",
    "    \n",
    "TotalMatches=soup.findAll('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "for i in TotalMatches:\n",
    "        Test.append(i.text)\n",
    "        \n",
    "Matches.extend(Test[0:-1:2])\n",
    "Points.extend(Test[1::2])\n",
    "\n",
    "\n",
    "TeamRatings=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    \n",
    "for i in TeamRatings:\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "Data={\"Rank\":Rank,\"Country Name\":Country,\"Matches Played\":Matches,\"Total Points\":Points,\"Country Rating\":Rating}\n",
    "\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "f54b753b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Player Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Beth, Mooney]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[Natalie, Sciver]</td>\n",
       "      <td>ENG</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[Laura, Wolvaardt]</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Meg, Lanning]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[Rachael, Haynes]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[Amy, Satterthwaite]</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[Tammy, Beaumont]</td>\n",
       "      <td>ENG</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[Chamari, Athapaththu]</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[Smriti, Mandhana]</td>\n",
       "      <td>IND</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank             Player Name Country Name Player Ratings\n",
       "0    1            Alyssa Healy          AUS            785\n",
       "1    2          [Beth, Mooney]          AUS            749\n",
       "2    3       [Natalie, Sciver]          ENG            747\n",
       "3    4      [Laura, Wolvaardt]           SA            732\n",
       "4    5          [Meg, Lanning]          AUS            710\n",
       "5    6       [Rachael, Haynes]          AUS            701\n",
       "6    7    [Amy, Satterthwaite]           NZ            681\n",
       "7    8       [Tammy, Beaumont]          ENG            667\n",
       "8    9  [Chamari, Athapaththu]           SL            655\n",
       "9   10      [Smriti, Mandhana]          IND            649"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "TestRank=[]\n",
    "TestName=[]\n",
    "TestCountry=[]\n",
    "TestRating=[]\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Country=[]\n",
    "Rating=[]\n",
    "\n",
    "BatRank=soup.find('span',class_='rankings-block__pos-number')\n",
    "TestRank.append(BatRank.text.split()[0])\n",
    "\n",
    "BatName=soup.find('div',class_='rankings-block__banner--name-large')\n",
    "TestName.append(BatName.text)\n",
    "\n",
    "BatCountry=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "TestCountry.append(BatCountry.text.split()[0])\n",
    "\n",
    "BatRating=soup.find('div',class_='rankings-block__banner--rating')\n",
    "TestRating.append(BatRating.text)\n",
    "\n",
    "BatRank=soup.findAll('span',class_='rankings-table__pos-number')\n",
    "for i in BatRank:\n",
    "    TestRank.append(i.text.split()[0])\n",
    "    Rank=TestRank[0:10]\n",
    "\n",
    "BatName=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for i in BatName:\n",
    "    TestName.append(i.text.split())\n",
    "    Name=TestName[0:10]\n",
    "    \n",
    "BatCountry=soup.find_all('span',class_='table-body__logo-text')\n",
    "for i in BatCountry:\n",
    "    TestCountry.append(i.text.split()[0])\n",
    "    Country=TestCountry[0:10]\n",
    "    \n",
    "    \n",
    "BatRating=soup.find_all('td',class_='table-body__cell rating')\n",
    "for i in BatRating:\n",
    "    TestRating.append(i.text)\n",
    "    Rating=TestRating[0:10]\n",
    "    \n",
    "    \n",
    "Data={\"Rank\":Rank,\"Player Name\":Name,\"Country Name\":Country,\"Player Ratings\":Rating}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "7b947ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Player Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Jess, Jonassen]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[Megan, Schutt]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[Shabnim, Ismail]</td>\n",
       "      <td>SA</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Jhulan, Goswami]</td>\n",
       "      <td>IND</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[Ayabonga, Khaka]</td>\n",
       "      <td>SA</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[Rajeshwari, Gayakwad]</td>\n",
       "      <td>IND</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[Hayley, Matthews]</td>\n",
       "      <td>WI</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>[Katherine, Brunt]</td>\n",
       "      <td>ENG</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>[Marizanne, Kapp]</td>\n",
       "      <td>SA</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank             Player Name Country Name Player Ratings\n",
       "0    1       Sophie Ecclestone          ENG            761\n",
       "1    2        [Jess, Jonassen]          AUS            725\n",
       "2    3         [Megan, Schutt]          AUS            722\n",
       "3    4       [Shabnim, Ismail]           SA            722\n",
       "4    5       [Jhulan, Goswami]          IND            644\n",
       "5    6       [Ayabonga, Khaka]           SA            634\n",
       "6    7  [Rajeshwari, Gayakwad]          IND            613\n",
       "7    8      [Hayley, Matthews]           WI            612\n",
       "8    9      [Katherine, Brunt]          ENG            601\n",
       "9   10       [Marizanne, Kapp]           SA            598"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "TestRank=[]\n",
    "TestName=[]\n",
    "TestCountry=[]\n",
    "TestRating=[]\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Country=[]\n",
    "Rating=[]\n",
    "\n",
    "BatRank=soup.find('span',class_='rankings-block__pos-number')\n",
    "TestRank.append(BatRank.text.split()[0])\n",
    "\n",
    "BatName=soup.find('div',class_='rankings-block__banner--name-large')\n",
    "TestName.append(BatName.text)\n",
    "\n",
    "BatCountry=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "TestCountry.append(BatCountry.text.split()[0])\n",
    "\n",
    "BatRating=soup.find('div',class_='rankings-block__banner--rating')\n",
    "TestRating.append(BatRating.text)\n",
    "\n",
    "BatRank=soup.findAll('span',class_='rankings-table__pos-number')\n",
    "for i in BatRank:\n",
    "    TestRank.append(i.text.split()[0])\n",
    "    Rank=TestRank[0:10]\n",
    "\n",
    "BatName=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "for i in BatName:\n",
    "    TestName.append(i.text.split())\n",
    "    Name=TestName[0:10]\n",
    "    \n",
    "BatCountry=soup.find_all('span',class_='table-body__logo-text')\n",
    "for i in BatCountry:\n",
    "    TestCountry.append(i.text.split()[0])\n",
    "    Country=TestCountry[0:10]\n",
    "    \n",
    "    \n",
    "BatRating=soup.find_all('td',class_='table-body__cell rating')\n",
    "for i in BatRating:\n",
    "    TestRating.append(i.text)\n",
    "    Rating=TestRating[0:10]\n",
    "    \n",
    "    \n",
    "Data={\"Rank\":Rank,\"Player Name\":Name,\"Country Name\":Country,\"Player Ratings\":Rating}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "ba7c25f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Headlines</th>\n",
       "      <th>Time of News</th>\n",
       "      <th>Link for News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This 39-year-old makes $160K/month in passive ...</td>\n",
       "      <td>12 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/this-39-year-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Most of Buffett’s portfolio is tied up in just...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/most-of-warren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 tips for cutting down on credit card costs a...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/how-to-curb-cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This 41-year-old left the U.S. for Bangkok and...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/this-digital-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's time to cash in on these attractive stock...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/goldman-analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Here's why getting fired from a job you hate c...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/therapist-gett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'Stressed out' STD clinics struggle with surge...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/monkeypox-std-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Want to build generational wealth? Avoid these...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/building-gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A.I.-powered drug hunters are nearing a pivota...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/ai-powered-dru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The 2022 stock market doesn't have to repeat —...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/the-2022-stock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Berkshire reports operating earnings surge, bu...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/berkshire-hath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Why the best states for business may be the wo...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/state-worker-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Higher prices, skimpier portions and apps — ho...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/higher-prices-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What to know before 'unretiring' if you're on ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/social-securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Netflix is expanding its push into video games...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/netflixs-video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>There are 'more intelligent ways' for U.S. to ...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/speaker-pelosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>California DMV accuses Tesla of deceptive mark...</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/california-dmv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gig economy stocks pop after companies show st...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/uber-and-lyft-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Twitter-Musk drama escalates in legal filings ...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/twitter-musk-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CNBC in 5 minutes: Here are all the stock call...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/cnbc-in-5-minu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>More Americans worked part-time last month as ...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/july-jobs-repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Big Oil is giving back tons of cash — and othe...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/investing-club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Investing Club: The week in review, the week a...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/investing-club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Schumer says Sinema left 'no choice' but to cu...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/sinema-made-sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Danger ahead: The U.S. economy has yet to face...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/danger-ahead-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Wharton professor: The key to influencing peop...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/wharton-profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Retirees may be focusing on wrong risks to fin...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/retirees-may-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What to watch in the markets in the week ahead</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/inflation-take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Here are 5 stocks in our portfolio that can be...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/investing-club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SpaceX raises another $250 million in equity, ...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/05/elon-musks-spa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       News Headlines  Time of News  \\\n",
       "0   This 39-year-old makes $160K/month in passive ...    12 Min Ago   \n",
       "1   Most of Buffett’s portfolio is tied up in just...    1 Hour Ago   \n",
       "2   5 tips for cutting down on credit card costs a...    1 Hour Ago   \n",
       "3   This 41-year-old left the U.S. for Bangkok and...   2 Hours Ago   \n",
       "4   It's time to cash in on these attractive stock...   2 Hours Ago   \n",
       "5   Here's why getting fired from a job you hate c...   2 Hours Ago   \n",
       "6   'Stressed out' STD clinics struggle with surge...   2 Hours Ago   \n",
       "7   Want to build generational wealth? Avoid these...   2 Hours Ago   \n",
       "8   A.I.-powered drug hunters are nearing a pivota...   2 Hours Ago   \n",
       "9   The 2022 stock market doesn't have to repeat —...   2 Hours Ago   \n",
       "10  Berkshire reports operating earnings surge, bu...   2 Hours Ago   \n",
       "11  Why the best states for business may be the wo...   3 Hours Ago   \n",
       "12  Higher prices, skimpier portions and apps — ho...   3 Hours Ago   \n",
       "13  What to know before 'unretiring' if you're on ...   3 Hours Ago   \n",
       "14  Netflix is expanding its push into video games...   3 Hours Ago   \n",
       "15  There are 'more intelligent ways' for U.S. to ...  12 Hours Ago   \n",
       "16  California DMV accuses Tesla of deceptive mark...  15 Hours Ago   \n",
       "17  Gig economy stocks pop after companies show st...  17 Hours Ago   \n",
       "18  Twitter-Musk drama escalates in legal filings ...  17 Hours Ago   \n",
       "19  CNBC in 5 minutes: Here are all the stock call...  17 Hours Ago   \n",
       "20  More Americans worked part-time last month as ...  18 Hours Ago   \n",
       "21  Big Oil is giving back tons of cash — and othe...  18 Hours Ago   \n",
       "22  Investing Club: The week in review, the week a...  19 Hours Ago   \n",
       "23  Schumer says Sinema left 'no choice' but to cu...  19 Hours Ago   \n",
       "24  Danger ahead: The U.S. economy has yet to face...  19 Hours Ago   \n",
       "25  Wharton professor: The key to influencing peop...  19 Hours Ago   \n",
       "26  Retirees may be focusing on wrong risks to fin...  19 Hours Ago   \n",
       "27     What to watch in the markets in the week ahead  19 Hours Ago   \n",
       "28  Here are 5 stocks in our portfolio that can be...  20 Hours Ago   \n",
       "29  SpaceX raises another $250 million in equity, ...  20 Hours Ago   \n",
       "\n",
       "                                        Link for News  \n",
       "0   https://www.cnbc.com/2022/08/06/this-39-year-o...  \n",
       "1   https://www.cnbc.com/2022/08/06/most-of-warren...  \n",
       "2   https://www.cnbc.com/2022/08/06/how-to-curb-cr...  \n",
       "3   https://www.cnbc.com/2022/08/06/this-digital-n...  \n",
       "4   https://www.cnbc.com/2022/08/06/goldman-analys...  \n",
       "5   https://www.cnbc.com/2022/08/06/therapist-gett...  \n",
       "6   https://www.cnbc.com/2022/08/06/monkeypox-std-...  \n",
       "7   https://www.cnbc.com/2022/08/06/building-gener...  \n",
       "8   https://www.cnbc.com/2022/08/06/ai-powered-dru...  \n",
       "9   https://www.cnbc.com/2022/08/06/the-2022-stock...  \n",
       "10  https://www.cnbc.com/2022/08/06/berkshire-hath...  \n",
       "11  https://www.cnbc.com/2022/08/06/state-worker-p...  \n",
       "12  https://www.cnbc.com/2022/08/06/higher-prices-...  \n",
       "13  https://www.cnbc.com/2022/08/06/social-securit...  \n",
       "14  https://www.cnbc.com/2022/08/06/netflixs-video...  \n",
       "15  https://www.cnbc.com/2022/08/06/speaker-pelosi...  \n",
       "16  https://www.cnbc.com/2022/08/05/california-dmv...  \n",
       "17  https://www.cnbc.com/2022/08/05/uber-and-lyft-...  \n",
       "18  https://www.cnbc.com/2022/08/05/twitter-musk-d...  \n",
       "19  https://www.cnbc.com/2022/08/05/cnbc-in-5-minu...  \n",
       "20  https://www.cnbc.com/2022/08/05/july-jobs-repo...  \n",
       "21  https://www.cnbc.com/2022/08/05/investing-club...  \n",
       "22  https://www.cnbc.com/2022/08/05/investing-club...  \n",
       "23  https://www.cnbc.com/2022/08/05/sinema-made-sc...  \n",
       "24  https://www.cnbc.com/2022/08/05/danger-ahead-t...  \n",
       "25  https://www.cnbc.com/2022/08/05/wharton-profes...  \n",
       "26  https://www.cnbc.com/2022/08/05/retirees-may-b...  \n",
       "27  https://www.cnbc.com/2022/08/05/inflation-take...  \n",
       "28  https://www.cnbc.com/2022/08/05/investing-club...  \n",
       "29  https://www.cnbc.com/2022/08/05/elon-musks-spa...  "
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "# i) Headline\n",
    "# ii) Time\n",
    "# iii) News Link\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "HeadLine=[]\n",
    "Time=[]\n",
    "Link=[]\n",
    "\n",
    "\n",
    "for i in soup.find_all('a',class_='LatestNews-headline'):\n",
    "    HeadLine.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('time',class_='LatestNews-timestamp'):\n",
    "    Time.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('a',class_='LatestNews-headline'):\n",
    "    Link.append(i.get('href'))\n",
    "\n",
    "    \n",
    "Data={'News Headlines':HeadLine,'Time of News':Time,'Link for News':Link}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b59e40ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "# https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "# Scrape below mentioned details :\n",
    "# i) Paper Title\n",
    "# ii) Authors\n",
    "# iii) Published Date\n",
    "# iv) Paper URL\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "Test=[]\n",
    "Title=[]\n",
    "Writers=[]\n",
    "Date=[]\n",
    "Links=[]\n",
    "\n",
    "Test=soup.find_all('h2',class_='sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR')\n",
    "for i in Test:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "Test=soup.find_all('span',class_='sc-1w3fpd7-0 pgLAT')\n",
    "for i in Test:\n",
    "    Writers.append(i.text)\n",
    "    \n",
    "Test=soup.find_all('span',class_='sc-1thf9ly-2 bKddwo')\n",
    "for i in Test:\n",
    "    Date.append(i.text)\n",
    "    \n",
    "for i in soup.find_all('a',class_='sc-5smygv-0 nrDZj'):\n",
    "    Links.append(i.get('href'))\n",
    "\n",
    "\n",
    "\n",
    "Data={'Paper Title':Title,'Authors':Writers,'Published Date':Date,'Paper URL':Links}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "d154003e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resturants Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>[Chinese,, North, Indian]</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>[North, Indian,, Asian,, Italian]</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>[Chinese,, North, Indian]</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>[Italian,, Continental]</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>[North, Indian,, Chinese]</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>[North, Indian,, Italian]</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>[North, Indian]</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>[North, Indian]</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>[North, Indian,, Mughlai]</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Resturants Name                            Cuisine  \\\n",
       "0                   Castle Barbeque          [Chinese,, North, Indian]   \n",
       "1                   Jungle Jamboree  [North, Indian,, Asian,, Italian]   \n",
       "2                   Castle Barbeque          [Chinese,, North, Indian]   \n",
       "3                        Cafe Knosh            [Italian,, Continental]   \n",
       "4              The Barbeque Company          [North, Indian,, Chinese]   \n",
       "5                       India Grill          [North, Indian,, Italian]   \n",
       "6                    Delhi Barbeque                    [North, Indian]   \n",
       "7  The Monarch - Bar Be Que Village                    [North, Indian]   \n",
       "8                 Indian Grill Room          [North, Indian,, Mughlai]   \n",
       "\n",
       "                                            Location Rating  \\\n",
       "0                     Connaught Place, Central Delhi    4.1   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi    3.9   \n",
       "2             Pacific Mall,Tagore Garden, West Delhi    3.9   \n",
       "3  The Leela Ambience Convention Hotel,Shahdara, ...    4.3   \n",
       "4                 Gardens Galleria,Sector 38A, Noida      4   \n",
       "5               Hilton Garden Inn,Saket, South Delhi    3.9   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi    3.7   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad    3.8   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon    4.3   \n",
       "\n",
       "                                           Image URL  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape mentioned details from dineout.co.in :\n",
    "# i) Restaurant name\n",
    "# ii) Cuisine\n",
    "# iii) Location\n",
    "# iv) Ratings\n",
    "# v) Image URL\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "Test=[]\n",
    "Resturants=[]\n",
    "Cuisine=[]\n",
    "Location=[]\n",
    "Stars=[]\n",
    "Image=[]\n",
    "\n",
    "Test=soup.find_all('a',class_='restnt-name ellipsis')\n",
    "for i in Test:\n",
    "    Resturants.append(i.text)\n",
    "\n",
    "    \n",
    "Test=soup.find_all('div',class_='restnt-loc ellipsis')\n",
    "for i in Test:\n",
    "    Location.append(i.text)\n",
    "    \n",
    "Test=soup.find_all('span',class_='double-line-ellipsis')\n",
    "for i in Test:\n",
    "    Cuisine.append(i.text.split()[6::])\n",
    "    \n",
    "    \n",
    "Test=soup.find_all('div',class_='restnt-rating rating-4')\n",
    "for i in Test:\n",
    "    Stars.append(i.text)\n",
    "\n",
    "for img in soup.find_all('img',class_='no-img'):\n",
    "    Image.append(img.get('data-src'))\n",
    "\n",
    "    \n",
    "Data={'Resturants Name':Resturants,'Cuisine':Cuisine,'Location':Location,'Rating':Stars,'Image URL':Image}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "851595f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-Index</th>\n",
       "      <th>h5-Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5-Index h5-Median\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape the details of top publications from Google Scholar from\n",
    "#   https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "# i) Rank\n",
    "# ii) Publication\n",
    "# iii) h5-index\n",
    "# iv) h5-median\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://scholar.google.com/citations?view_op=top_venues&hl=en'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "Test=[]\n",
    "Rank=[]\n",
    "Titles=[]\n",
    "Avg=[]\n",
    "Median=[]\n",
    "\n",
    "Test=soup.find_all('td',class_='gsc_mvt_p')\n",
    "for i in Test:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "    \n",
    "\n",
    "Test=soup.find_all('td',class_='gsc_mvt_t')\n",
    "for i in Test:\n",
    "    Titles.append(i.text)\n",
    "\n",
    "    \n",
    "Test=soup.find_all('a',class_='gs_ibl gsc_mp_anchor')\n",
    "for i in Test:\n",
    "    Avg.append(i.text)\n",
    "    \n",
    "\n",
    "Test=soup.find_all('span',class_='gs_ibl gsc_mp_anchor')\n",
    "for i in Test:\n",
    "    Median.append(i.text)\n",
    "\n",
    "\n",
    "    \n",
    "Data={'Rank':Rank,'Publication':Titles,'h5-Index':Avg,'h5-Median':Median}\n",
    "\n",
    "df=pd.DataFrame(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada43d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
